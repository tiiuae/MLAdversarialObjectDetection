{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea62a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def allow_direct_imports_from(dirname):\n",
    "    import sys\n",
    "    if dirname not in sys.path:\n",
    "        sys.path.append(dirname)\n",
    "        \n",
    "allow_direct_imports_from('automl/efficientdet')\n",
    "\n",
    "import os, shutil, matplotlib.pyplot as plt, tensorflow as tf\n",
    "import tf2.infer_lib as infer_lib, util, custom_callbacks, train_data_generator, dynamicattacker as attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271c83e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = 'efficientdet-lite4'\n",
    "\n",
    "def main(download_model=False):\n",
    "    log_dir = util.ensure_empty_dir('log_dir')\n",
    "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    victim_model = util.get_victim_model(MODEL, download_model)\n",
    "    config_override = {'nms_configs': {'iou_thresh': .5, 'score_thresh': .5},\n",
    "                       'image_size': 480}\n",
    "    model = attacker.DynamicPatchAttacker(victim_model,\n",
    "                                          initial_weights='save_dir/pa',\n",
    "                                          config_override=config_override,\n",
    "                                          visualize_freq=200)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-3), run_eagerly=False)\n",
    "\n",
    "    datasets: dict = train_data_generator.partition(model.config, 'downloaded_images', 'labels',\n",
    "                                                               batch_size=24, shuffle=True)\n",
    "\n",
    "    train_ds = datasets['train']['dataset']\n",
    "    val_ds = datasets['val']['dataset']\n",
    "    train_len = datasets['train']['length']\n",
    "    val_len = datasets['val']['length']\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir, write_graph=False,\n",
    "                                                 write_steps_per_second=True,\n",
    "                                                 update_freq='epoch')\n",
    "    model.tb = tb_callback\n",
    "\n",
    "    save_dir = util.ensure_empty_dir('save_dir')\n",
    "    save_file = 'patch_{epoch:02d}_{val_mean_score_delta:.4f}'\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=100, steps_per_epoch=train_len,\n",
    "#                         initial_epoch=12,\n",
    "                        validation_steps=val_len,\n",
    "                        callbacks=[tb_callback,\n",
    "                                   tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, save_file),\n",
    "                                                                      monitor='val_loss',\n",
    "                                                                      verbose=1,\n",
    "                                                                      save_best_only=False,\n",
    "                                                                      save_weights_only=True,\n",
    "                                                                      mode='auto',\n",
    "                                                                      save_freq='epoch',\n",
    "                                                                      options=None,\n",
    "                                                                      initial_value_threshold=None\n",
    "                                                                      ),\n",
    "                                   tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', verbose=1, factor=.5, min_lr=1e-5)\n",
    "                                   ])\n",
    "    \n",
    "    return hist, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab01f34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hist, model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdb838",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def allow_direct_imports_from(dirname):\n",
    "    import sys\n",
    "    if dirname not in sys.path:\n",
    "        sys.path.append(dirname)\n",
    "\n",
    "allow_direct_imports_from('automl/efficientdet')\n",
    "\n",
    "import os, shutil, tensorflow as tf\n",
    "import tf2.infer_lib as infer_lib, util, custom_callbacks, train_data_generator, attack_detection_v2 as defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28313ff2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = 'efficientdet-lite4'\n",
    "\n",
    "def main(download_model=False):\n",
    "    log_dir = util.ensure_empty_dir('log_dir')\n",
    "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    victim_model = util.get_victim_model(MODEL, download_model)\n",
    "    config_override = {'nms_configs': {'iou_thresh': .5, 'score_thresh': .5},\n",
    "                       'image_size': 480}\n",
    "    model = defender.PatchAttackDefender(victim_model,\n",
    "#                                           initial_weights='save_dir/patch_04_0.5024',\n",
    "                                         eval_patch_weights='save_dir_rand_print_dropout/patch_100_0.6910',\n",
    "                                          config_override=config_override,\n",
    "                                          visualize_freq=50)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), run_eagerly=False)\n",
    "\n",
    "    datasets: dict = train_data_generator.partition(model.config, 'downloaded_images', 'labels',\n",
    "                                                               batch_size=64, shuffle=True)\n",
    "\n",
    "    train_ds = datasets['train']['dataset']\n",
    "    val_ds = datasets['val']['dataset']\n",
    "    train_len = datasets['train']['length']\n",
    "    val_len = datasets['val']['length']\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir, write_graph=False,\n",
    "                                                 write_steps_per_second=True,\n",
    "                                                 update_freq='epoch')\n",
    "    model.tb = tb_callback\n",
    "\n",
    "    save_dir = util.ensure_empty_dir('save_dir')\n",
    "    save_file = 'patch_{epoch:02d}_{val_loss:.4f}'\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=100, steps_per_epoch=train_len,\n",
    "#                         initial_epoch=12,\n",
    "                        validation_steps=val_len,\n",
    "                        callbacks=[tb_callback,\n",
    "                                   tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, save_file),\n",
    "                                                                      monitor='val_loss',\n",
    "                                                                      verbose=1,\n",
    "                                                                      save_best_only=False,\n",
    "                                                                      save_weights_only=True,\n",
    "                                                                      mode='auto',\n",
    "                                                                      save_freq='epoch',\n",
    "                                                                      options=None,\n",
    "                                                                      initial_value_threshold=None\n",
    "                                                                      ),\n",
    "                                   tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', verbose=1, factor=.5, min_lr=1e-5)\n",
    "                                   ])\n",
    "    \n",
    "    return hist, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2178c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hist, model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846e77d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def allow_direct_imports_from(dirname):\n",
    "    import sys\n",
    "    if dirname not in sys.path:\n",
    "        sys.path.append(dirname)\n",
    "\n",
    "allow_direct_imports_from('automl/efficientdet')\n",
    "\n",
    "import os, shutil, tensorflow as tf\n",
    "import tf2.infer_lib as infer_lib, util, custom_callbacks, train_data_generator, attack_detection_v2 as defender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63d5d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = 'efficientdet-lite4'\n",
    "\n",
    "def main(download_model=False):\n",
    "    log_dir = util.ensure_empty_dir('log_dir')\n",
    "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    victim_model = util.get_victim_model(MODEL, download_model)\n",
    "    config_override = {'nms_configs': {'iou_thresh': .5, 'score_thresh': .5},\n",
    "                       'image_size': 480}\n",
    "    model = defender.PatchAttackDefender(victim_model,\n",
    "#                                           initial_weights='save_dir/patch_04_0.5024',\n",
    "                                         eval_patch_weights='save_dir_rand_print_dropout/patch_100_0.6910',\n",
    "                                          config_override=config_override,\n",
    "                                          visualize_freq=50)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), run_eagerly=False)\n",
    "\n",
    "    datasets: dict = train_data_generator.partition(model.config, 'downloaded_images', 'labels',\n",
    "                                                               batch_size=64, shuffle=True)\n",
    "\n",
    "    train_ds = datasets['train']['dataset']\n",
    "    val_ds = datasets['val']['dataset']\n",
    "    train_len = datasets['train']['length']\n",
    "    val_len = datasets['val']['length']\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir, write_graph=False,\n",
    "                                                 write_steps_per_second=True,\n",
    "                                                 update_freq='epoch')\n",
    "    model.tb = tb_callback\n",
    "\n",
    "    save_dir = util.ensure_empty_dir('save_dir')\n",
    "    save_file = 'patch_{epoch:02d}_{val_loss:.4f}'\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=100, steps_per_epoch=train_len,\n",
    "#                         initial_epoch=12,\n",
    "                        validation_steps=val_len,\n",
    "                        callbacks=[tb_callback,\n",
    "                                   tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, save_file),\n",
    "                                                                      monitor='val_loss',\n",
    "                                                                      verbose=1,\n",
    "                                                                      save_best_only=False,\n",
    "                                                                      save_weights_only=True,\n",
    "                                                                      mode='auto',\n",
    "                                                                      save_freq='epoch',\n",
    "                                                                      options=None,\n",
    "                                                                      initial_value_threshold=None\n",
    "                                                                      ),\n",
    "                                   tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', verbose=1, factor=.5, min_lr=1e-5)\n",
    "                                   ])\n",
    "    \n",
    "    return hist, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a769f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hist, model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf25eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737f42c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T18:19:56.217675Z",
     "start_time": "2022-06-10T18:19:56.210702Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL = 'efficientdet-lite4'\n",
    "\n",
    "def main(download_model=False):\n",
    "    log_dir = util.ensure_empty_dir('log_dir')\n",
    "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    victim_model = util.get_victim_model(MODEL, download_model)\n",
    "    config_override = {'nms_configs': {'iou_thresh': .5, 'score_thresh': .5},\n",
    "                       'image_size': 480}\n",
    "    model = defender.PatchAttackDefender(victim_model,\n",
    "#                                           initial_weights='save_dir/patch_04_0.5024',\n",
    "                                         eval_patch_weights='save_dir_rand_print_dropout/patch_100_0.6910',\n",
    "                                          config_override=config_override,\n",
    "                                          visualize_freq=50)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), run_eagerly=False)\n",
    "\n",
    "    datasets: dict = train_data_generator.partition(model.config, 'downloaded_images', 'labels',\n",
    "                                                               batch_size=64, shuffle=True)\n",
    "\n",
    "    train_ds = datasets['train']['dataset']\n",
    "    val_ds = datasets['val']['dataset']\n",
    "    train_len = datasets['train']['length']\n",
    "    val_len = datasets['val']['length']\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir, write_graph=False,\n",
    "                                                 write_steps_per_second=True,\n",
    "                                                 update_freq='epoch')\n",
    "    model.tb = tb_callback\n",
    "\n",
    "    save_dir = util.ensure_empty_dir('save_dir')\n",
    "    save_file = 'patch_{epoch:02d}_{val_loss:.4f}'\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=100, steps_per_epoch=train_len,\n",
    "#                         initial_epoch=12,\n",
    "                        validation_steps=val_len,\n",
    "                        callbacks=[tb_callback,\n",
    "                                   tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, save_file),\n",
    "                                                                      monitor='val_loss',\n",
    "                                                                      verbose=1,\n",
    "                                                                      save_best_only=False,\n",
    "                                                                      save_weights_only=True,\n",
    "                                                                      mode='auto',\n",
    "                                                                      save_freq='epoch',\n",
    "                                                                      options=None,\n",
    "                                                                      initial_value_threshold=None\n",
    "                                                                      ),\n",
    "                                   tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', verbose=1, factor=.5, min_lr=1e-5)\n",
    "                                   ])\n",
    "    \n",
    "    return hist, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a079d4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-10T18:19:56.694Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/__autograph_generated_filegvy0pzz2.py:23: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  ag__.for_stmt(ag__.ld(self).updates, None, loop_body, get_state, set_state, (), {'iterate_names': 'u'})\n",
      "/phyadv/automl/efficientdet/utils.py:255: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  for u in self.updates:\n",
      "filtering dataset by label constraints...\n",
      "done. data size is 64115\n",
      "training on 51292 images, validating on 6411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - ETA: 0s - loss: 1.8574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/__autograph_generated_filegvy0pzz2.py:23: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  ag__.for_stmt(ag__.ld(self).updates, None, loop_body, get_state, set_state, (), {'iterate_names': 'u'})\n",
      "/phyadv/automl/efficientdet/utils.py:255: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  for u in self.updates:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Note that RandomUniform inside pfor op may not give same output as inside a sequential loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to save_dir/patch_01_1.8400\n",
      "802/802 [==============================] - 1097s 1s/step - loss: 1.8574 - val_loss: 1.8400 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.9391\n",
      "Epoch 2: saving model to save_dir/patch_02_3.4201\n",
      "802/802 [==============================] - 1039s 1s/step - loss: 0.9391 - val_loss: 3.4201 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.8387\n",
      "Epoch 3: saving model to save_dir/patch_03_6.1951\n",
      "802/802 [==============================] - 1038s 1s/step - loss: 0.8387 - val_loss: 6.1951 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.7879\n",
      "Epoch 4: saving model to save_dir/patch_04_22.3647\n",
      "802/802 [==============================] - 1038s 1s/step - loss: 0.7879 - val_loss: 22.3647 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.7568\n",
      "Epoch 5: saving model to save_dir/patch_05_21.6993\n",
      "802/802 [==============================] - 1037s 1s/step - loss: 0.7568 - val_loss: 21.6993 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.7296\n",
      "Epoch 6: saving model to save_dir/patch_06_7.5799\n",
      "802/802 [==============================] - 1037s 1s/step - loss: 0.7296 - val_loss: 7.5799 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.7127\n",
      "Epoch 7: saving model to save_dir/patch_07_7.5023\n",
      "802/802 [==============================] - 1037s 1s/step - loss: 0.7127 - val_loss: 7.5023 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.6896\n",
      "Epoch 8: saving model to save_dir/patch_08_10.8757\n",
      "802/802 [==============================] - 1036s 1s/step - loss: 0.6896 - val_loss: 10.8757 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.6880\n",
      "Epoch 9: saving model to save_dir/patch_09_2.2585\n",
      "802/802 [==============================] - 1037s 1s/step - loss: 0.6880 - val_loss: 2.2585 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.6691\n",
      "Epoch 10: saving model to save_dir/patch_10_4.2917\n",
      "802/802 [==============================] - 1035s 1s/step - loss: 0.6691 - val_loss: 4.2917 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "317/802 [==========>...................] - ETA: 9:10 - loss: 0.6744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - ETA: 0s - loss: 0.6194\n",
      "Epoch 26: saving model to save_dir/patch_26_7.9850\n",
      "802/802 [==============================] - 1039s 1s/step - loss: 0.6194 - val_loss: 7.9850 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.6273\n",
      "Epoch 27: saving model to save_dir/patch_27_11.4455\n",
      "802/802 [==============================] - 1036s 1s/step - loss: 0.6273 - val_loss: 11.4455 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "753/802 [===========================>..] - ETA: 55s - loss: 0.6258\n",
      "Epoch 28: saving model to save_dir/patch_28_4.3121\n",
      "802/802 [==============================] - 1037s 1s/step - loss: 0.6248 - val_loss: 4.3121 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "525/802 [==================>...........] - ETA: 5:15 - loss: 0.6178"
     ]
    }
   ],
   "source": [
    "hist, model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31220588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
